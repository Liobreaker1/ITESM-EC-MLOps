{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OAi4fsNUTe9E"},"outputs":[],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.pipeline import Pipeline\n","\n","from sklearn.metrics import accuracy_score, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLJCN_mzTe9I"},"outputs":[],"source":["DATASETS_DIR = 'datasets/'\n","URL = 'https://www.openml.org/data/get_csv/16826755/phpMYEkMl'\n","DROP_COLS = ['boat','body','home.dest','ticket','name']\n","RETRIEVED_DATA = 'raw-data.csv'\n","\n","\n","SEED_SPLIT = 404\n","TRAIN_DATA_FILE = DATASETS_DIR + 'train.csv'\n","TEST_DATA_FILE  = DATASETS_DIR + 'test.csv'\n","\n","\n","TARGET = 'survived'\n","FEATURES = ['pclass','sex','age','sibsp','parch','fare','cabin','embarked','title']\n","NUMERICAL_VARS = ['pclass','age','sibsp','parch','fare']\n","CATEGORICAL_VARS = ['sex','cabin','embarked','title']\n","\n","\n","NUMERICAL_VARS_WITH_NA = ['age','fare']\n","CATEGORICAL_VARS_WITH_NA = ['cabin','embarked']\n","NUMERICAL_NA_NOT_ALLOWED = [var for var in NUMERICAL_VARS if var not in NUMERICAL_VARS_WITH_NA]\n","CATEGORICAL_NA_NOT_ALLOWED = [var for var in CATEGORICAL_VARS if var not in CATEGORICAL_VARS_WITH_NA]\n","\n","\n","SEED_MODEL = 404"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LReW4_6ZTe9J"},"outputs":[],"source":["def data_retrieval(url):\n","\n","    # Loading data from specific url\n","    data = pd.read_csv(url)\n","\n","    # Uncovering missing data\n","    data.replace('?', np.nan, inplace=True)\n","    data['age'] = data['age'].astype('float')\n","    data['fare'] = data['fare'].astype('float')\n","\n","    # helper function 1\n","    def get_first_cabin(row):\n","        try:\n","            return row.split()[0]\n","        except:\n","            return np.nan\n","\n","    # helper function 2\n","    def get_title(passenger):\n","        line = passenger\n","        if re.search('Mrs', line):\n","            return 'Mrs'\n","        elif re.search('Mr', line):\n","            return 'Mr'\n","        elif re.search('Miss', line):\n","            return 'Miss'\n","        elif re.search('Master', line):\n","            return 'Master'\n","        else:\n","            return 'Other'\n","\n","    # Keep only one cabin | Extract the title from 'name'\n","    data['cabin'] = data['cabin'].apply(get_first_cabin)\n","    data['title'] = data['name'].apply(get_title)\n","\n","    # Droping irrelevant columns\n","    data.drop(DROP_COLS, 1, inplace=True)\n","\n","    data.to_csv(DATASETS_DIR + RETRIEVED_DATA, index=False)\n","\n","    return print('Data stored in {}'.format(DATASETS_DIR + RETRIEVED_DATA))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kO20nbhbTe9J"},"outputs":[],"source":["class MissingIndicator(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var+'_nan'] = X[var].isnull().astype(int)\n","\n","        return X\n","\n","\n","class ExtractLetters(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self):\n","        self.variable = 'cabin'\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        X[self.variable] = X[self.variable].apply(lambda x: ''.join(re.findall(\"[a-zA-Z]+\", x)) if type(x)==str else x)\n","        return X\n","\n","\n","class CategoricalImputer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var] = X[var].fillna('Missing')\n","        return X\n","\n","\n","class NumericalImputer(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        self.median_dict_ = {}\n","        for var in self.variables:\n","            self.median_dict_[var] = X[var].median()\n","        return self\n","\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var] = X[var].fillna(self.median_dict_[var])\n","        return X\n","\n","\n","class RareLabelCategoricalEncoder(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, tol=0.05, variables=None):\n","        self.tol = tol\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        self.rare_labels_dict = {}\n","        for var in self.variables:\n","            t = pd.Series(X[var].value_counts() / np.float(X.shape[0]))\n","            self.rare_labels_dict[var] = list(t[t<self.tol].index)\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        for var in self.variables:\n","            X[var] = np.where(X[var].isin(self.rare_labels_dict[var]), 'rare', X[var])\n","        return X\n","\n","\n","class OneHotEncoder(BaseEstimator, TransformerMixin):\n","\n","    def __init__(self, variables=None):\n","        if not isinstance(variables, list):\n","            self.variables = [variables]\n","        else:\n","            self.variables = variables\n","\n","    def fit(self, X, y=None):\n","        self.dummies = pd.get_dummies(X[self.variables], drop_first=True).columns\n","        return self\n","\n","    def transform(self, X):\n","        X = X.copy()\n","        X = pd.concat([X, pd.get_dummies(X[self.variables], drop_first=True)], 1)\n","        X.drop(self.variables, 1, inplace=True)\n","\n","        # Adding missing dummies, if any\n","        missing_dummies = [var for var in self.dummies if var not in X.columns]\n","        if len(missing_dummies) != 0:\n","            for col in missing_dummies:\n","                X[col] = 0\n","\n","        return X\n","\n","\n","class OrderingFeatures(BaseEstimator, TransformerMixin):\n","    def __init__(self):\n","        return None\n","\n","    def fit(self, X, y=None):\n","        self.ordered_features = X.columns\n","        return self\n","\n","    def transform(self, X):\n","        return X[self.ordered_features]\n","\n","\n","# scaler = MinMaxScaler()\n","# scaler.fit(X_train)\n","# X_train = scaler.transform(X_train)\n","# X_test  = scaler.transform(X_test)\n","\n","# model = LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL)\n","# model.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oopemkFqTe9K"},"outputs":[],"source":["titanic_pipeline = Pipeline(\n","                              [\n","                                ('missing_indicator', MissingIndicator(variables=NUMERICAL_VARS)),\n","                                ('cabin_only_letter', ExtractLetters()),\n","                                ('categorical_imputer', CategoricalImputer(variables=CATEGORICAL_VARS_WITH_NA)),\n","                                ('median_imputation', NumericalImputer(variables=NUMERICAL_VARS_WITH_NA)),\n","                                ('rare_labels', RareLabelCategoricalEncoder(tol=0.05, variables=CATEGORICAL_VARS)),\n","                                ('dummy_vars', OneHotEncoder(variables=CATEGORICAL_VARS)),\n","                                ('aligning_feats', OrderingFeatures()),\n","                                ('scaling', MinMaxScaler()),\n","                                ('log_reg', LogisticRegression(C=0.0005, class_weight='balanced', random_state=SEED_MODEL))\n","                              ])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"FVjJM89lTe9L","executionInfo":{"status":"error","timestamp":1690930505405,"user_tz":360,"elapsed":1223,"user":{"displayName":"Carlos L. Mejia","userId":"10564897252390300631"}},"outputId":"1d354e33-62be-420f-d012-36efd01f23df"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-f4f31f90b227>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASETS_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mRETRIEVED_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[1;32m      4\u001b[0m                                                         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTARGET\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/raw-data.csv'"]}],"source":["df = pd.read_csv(DATASETS_DIR + RETRIEVED_DATA)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","                                                        df.drop(TARGET, axis=1),\n","                                                        df[TARGET],\n","                                                        test_size=0.2,\n","                                                        random_state=404\n","                                                   )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qjvH8cV8Te9L"},"outputs":[],"source":["titanic_pipeline.fit(X_train, y_train);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zk3VK_-DTe9M","outputId":"14f9ea69-6ac5-4824-eb7e-95c7d46e801d"},"outputs":[{"name":"stdout","output_type":"stream","text":["test roc-auc : 0.8163583073823043\n","test accuracy: 0.7748091603053435\n","\n"]}],"source":["class_pred = titanic_pipeline.predict(X_test)\n","proba_pred = titanic_pipeline.predict_proba(X_test)[:,1]\n","print('test roc-auc : {}'.format(roc_auc_score(y_test, proba_pred)))\n","print('test accuracy: {}'.format(accuracy_score(y_test, class_pred)))\n","print()"]},{"cell_type":"markdown","metadata":{"id":"ijdxGxE1Te9N"},"source":["## Persisting the trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VFheKbeLTe9O"},"outputs":[],"source":["import joblib\n","\n","TRAINED_MODEL_DIR = 'trained_models/'\n","PIPELINE_NAME = 'logistic_regression'\n","PIPELINE_SAVE_FILE = f'{PIPELINE_NAME}_output.pkl'\n","\n","save_file_name = f'{PIPELINE_SAVE_FILE}'\n","save_path = TRAINED_MODEL_DIR + save_file_name\n","\n","pipeline_to_persist = titanic_pipeline\n","\n","# joblib.dump(pipeline_to_persist, save_path)"]},{"cell_type":"markdown","metadata":{"id":"fBM64vZlTe9P"},"source":["## Predictions"]},{"cell_type":"markdown","metadata":{"id":"RSDnRpBcTe9P"},"source":["**Basic input validation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dJQOeIfgTe9P"},"outputs":[],"source":["input_data = X_test.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V1gcR2HbTe9P"},"outputs":[],"source":["validated_data = input_data\n","\n","if input_data[NUMERICAL_NA_NOT_ALLOWED].isnull().any().any():\n","        validated_data = validated_data.dropna(subset=NUMERICAL_NA_NOT_ALLOWED)\n","\n","if input_data[CATEGORICAL_NA_NOT_ALLOWED].isnull().any().any():\n","        validated_data = validated_data.dropna(subset=CATEGORICAL_NA_NOT_ALLOWED)"]},{"cell_type":"markdown","metadata":{"id":"m2WC7E3ZTe9P"},"source":["**Making predictions**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvRTcqheTe9Q"},"outputs":[],"source":["file_path = TRAINED_MODEL_DIR + PIPELINE_SAVE_FILE\n","trained_model = joblib.load(filename=file_path)\n","\n","preds = trained_model.predict(validated_data)\n","proba = trained_model.predict_proba(validated_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4aq0M7mTe9Q","outputId":"04cb338f-cf58-44ec-ed67-0730d2bd30ca"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>pclass</th>\n","      <th>sex</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>cabin</th>\n","      <th>embarked</th>\n","      <th>title</th>\n","      <th>preds</th>\n","      <th>probas</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>215</td>\n","      <td>1</td>\n","      <td>male</td>\n","      <td>58.0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>113.2750</td>\n","      <td>D48</td>\n","      <td>C</td>\n","      <td>Mr</td>\n","      <td>1</td>\n","      <td>0.502177</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>378</td>\n","      <td>2</td>\n","      <td>male</td>\n","      <td>31.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>26.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>Mr</td>\n","      <td>0</td>\n","      <td>0.481497</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>695</td>\n","      <td>3</td>\n","      <td>female</td>\n","      <td>18.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.8792</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","      <td>Miss</td>\n","      <td>1</td>\n","      <td>0.513358</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>414</td>\n","      <td>2</td>\n","      <td>male</td>\n","      <td>34.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>21.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>Mr</td>\n","      <td>0</td>\n","      <td>0.481422</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>509</td>\n","      <td>2</td>\n","      <td>male</td>\n","      <td>39.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>26.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","      <td>Mr</td>\n","      <td>0</td>\n","      <td>0.481452</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   index  pclass     sex   age  sibsp  parch      fare cabin embarked title  \\\n","0    215       1    male  58.0      0      2  113.2750   D48        C    Mr   \n","1    378       2    male  31.0      1      1   26.2500   NaN        S    Mr   \n","2    695       3  female  18.0      0      0    7.8792   NaN        Q  Miss   \n","3    414       2    male  34.0      1      0   21.0000   NaN        S    Mr   \n","4    509       2    male  39.0      0      0   26.0000   NaN        S    Mr   \n","\n","   preds    probas  \n","0      1  0.502177  \n","1      0  0.481497  \n","2      1  0.513358  \n","3      0  0.481422  \n","4      0  0.481452  "]},"execution_count":188,"metadata":{},"output_type":"execute_result"}],"source":["pd.concat([validated_data.reset_index(), pd.Series(preds, name='preds'), pd.Series(pd.DataFrame(proba)[1], name='probas')], 1).head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wsSiRjA2Te9Q"},"outputs":[],"source":["# preds == class_pred"]},{"cell_type":"markdown","metadata":{"id":"33fXEX7eTe9Q"},"source":["## Predictions with the model served as REST API"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzSaKQSQTe9Q","outputId":"ebea9c6a-bc37-44d3-b6a8-4c8ca4fc130c"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'errors': None, 'predictions': 1, 'probas': 0.5310253087423779, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5263773680278067, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5219452589901723, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5263026785829125, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5263332008249159, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5219136288521562, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5264846114230751, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5307701281686432, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5309518672521598, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5315805668982763, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5278059761556281, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5188765127026285, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5219261927703763, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5218960365962279, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5188348245858921, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.531499960268296, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5188774281569051, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5218741958797357, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5307649058908525, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5263489272390866, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.518862190790834, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5219256534077692, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.52636194917723, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.5218757886338191, 'version': '1.0.0'}\n","{'errors': None, 'predictions': 1, 'probas': 0.521885939521661, 'version': '1.0.0'}\n"]}],"source":["import json\n","import requests\n","\n","url = 'http://127.0.0.1:5000/v1/predict/classification'\n","headers = {'Content-type': 'application/json', 'Accept': 'text/plain'}\n","\n","data1 = {\"pclass\":1,\"sex\":\"male\",\"age\":58.0,\"sibsp\":0,\"parch\":2,\"fare\":113.275,\"cabin\":\"D48\",\"embarked\":\"C\",\"title\":\"Mr\"}\n","data2 = {\"pclass\":2,\"sex\":\"male\",\"age\":31.0,\"sibsp\":1,\"parch\":1,\"fare\":26.25,\"cabin\":None,\"embarked\":\"S\",\"title\":\"Mr\"}\n","data3 = {\"pclass\":3,\"sex\":\"female\",\"age\":18.0,\"sibsp\":0,\"parch\":0,\"fare\":7.8792,\"cabin\":None,\"embarked\":\"Q\",\"title\":\"Miss\"}\n","data4 = {\"pclass\":2,\"sex\":\"male\",\"age\":34.0,\"sibsp\":1,\"parch\":0,\"fare\":21.0,\"cabin\":None,\"embarked\":\"S\",\"title\":\"Mr\"}\n","data5 = {\"pclass\":2,\"sex\":\"male\",\"age\":39.0,\"sibsp\":0,\"parch\":0,\"fare\":26.0,\"cabin\":None,\"embarked\":\"S\",\"title\":\"Mr\"}\n","\n","for d in [X_test[i:i+1].to_json(orient='records') for i in range(25)]:\n","    info = json.loads(d)[0]\n","    x = requests.post(url, data=json.dumps(info), headers=headers)\n","    print(x.json())"]},{"cell_type":"markdown","metadata":{"id":"637h_J-yTe9Q"},"source":["## pd.DataFrame.from_dict([x.json()], orient='columns')"]},{"cell_type":"markdown","metadata":{"id":"pqqseJwSTe9R"},"source":["___"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-e-imJ5Te9R"},"outputs":[],"source":["# X_test.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJz8vKFsTe9R","outputId":"fc3da98f-fc25-4633-96a1-b3d6fedd7b3c"},"outputs":[{"data":{"text/plain":["dict"]},"execution_count":154,"metadata":{},"output_type":"execute_result"}],"source":["prueba = '{\"pclass\":1,\"sex\":\"male\",\"age\":58.0,\"sibsp\":0,\"parch\":2,\"fare\":113.275,\"cabin\":\"D48\",\"embarked\":\"C\",\"title\":\"Mr\"}'\n","type(json.loads(prueba) )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nAkUjTgJTe9R"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sduw1rlOTe9R"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyfZ-Il-Te9R"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sR_yce-NTe9R"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Or3RzrZQTe9R"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AesKuqLuTe9R"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wo24BGKETe9S"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1dfa2dmcTe9S"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bS4T1ExwTe9S"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IzsPcVcoTe9S"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBDK4iBrTe9S","outputId":"4ce04bee-7db9-48ff-fc14-8e4e6a6b7db8"},"outputs":[{"name":"stdout","output_type":"stream","text":["train roc-auc : 0.8470412710714978\n","train accuracy: 0.7831900668576887\n","\n","test roc-auc : 0.8163583073823043\n","test accuracy: 0.7748091603053435\n","\n"]}],"source":["for s,t in zip(['train','test'],[(X_train, y_train),(X_test,y_test)]):\n","    x,y = t[0], t[1]\n","    class_pred = model.predict(x)\n","    proba_pred = model.predict_proba(x)[:,1]\n","    print('{} roc-auc : {}'.format(s, roc_auc_score(y, proba_pred)))\n","    print('{} accuracy: {}'.format(s, accuracy_score(y, class_pred)))\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQ5B0D5oTe9S","outputId":"7540672e-6bef-493e-e308-a477fa67f57b"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pclass</th>\n","      <th>age</th>\n","      <th>sibsp</th>\n","      <th>parch</th>\n","      <th>fare</th>\n","      <th>pclass_nan</th>\n","      <th>age_nan</th>\n","      <th>sibsp_nan</th>\n","      <th>parch_nan</th>\n","      <th>fare_nan</th>\n","      <th>...</th>\n","      <th>cabin_rare</th>\n","      <th>embarked_Q</th>\n","      <th>embarked_S</th>\n","      <th>embarked_rare</th>\n","      <th>title_Mr</th>\n","      <th>title_Mrs</th>\n","      <th>title_rare</th>\n","      <th>y_true</th>\n","      <th>y_pred</th>\n","      <th>proba_pred</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>0.724426</td>\n","      <td>0.000</td>\n","      <td>0.222222</td>\n","      <td>0.221098</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.502177</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.5</td>\n","      <td>0.386221</td>\n","      <td>0.125</td>\n","      <td>0.111111</td>\n","      <td>0.051237</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.481497</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.223382</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.015379</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.513358</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.5</td>\n","      <td>0.423799</td>\n","      <td>0.125</td>\n","      <td>0.000000</td>\n","      <td>0.040989</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.481422</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.5</td>\n","      <td>0.486430</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.050749</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0.481452</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","      <td>0.298538</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.013940</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.477030</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.5</td>\n","      <td>0.160751</td>\n","      <td>0.000</td>\n","      <td>0.111111</td>\n","      <td>0.038061</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.514231</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.0</td>\n","      <td>0.611691</td>\n","      <td>0.125</td>\n","      <td>0.000000</td>\n","      <td>0.111118</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.501921</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.0</td>\n","      <td>0.398747</td>\n","      <td>0.000</td>\n","      <td>0.000000</td>\n","      <td>0.148911</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.534687</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.0</td>\n","      <td>0.260960</td>\n","      <td>0.250</td>\n","      <td>0.222222</td>\n","      <td>0.512122</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.531581</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 23 columns</p>\n","</div>"],"text/plain":["   pclass       age  sibsp     parch      fare  pclass_nan  age_nan  \\\n","0     0.0  0.724426  0.000  0.222222  0.221098         0.0      0.0   \n","1     0.5  0.386221  0.125  0.111111  0.051237         0.0      0.0   \n","2     1.0  0.223382  0.000  0.000000  0.015379         0.0      0.0   \n","3     0.5  0.423799  0.125  0.000000  0.040989         0.0      0.0   \n","4     0.5  0.486430  0.000  0.000000  0.050749         0.0      0.0   \n","5     1.0  0.298538  0.000  0.000000  0.013940         0.0      0.0   \n","6     0.5  0.160751  0.000  0.111111  0.038061         0.0      0.0   \n","7     0.0  0.611691  0.125  0.000000  0.111118         0.0      0.0   \n","8     0.0  0.398747  0.000  0.000000  0.148911         0.0      0.0   \n","9     0.0  0.260960  0.250  0.222222  0.512122         0.0      0.0   \n","\n","   sibsp_nan  parch_nan  fare_nan  ...  cabin_rare  embarked_Q  embarked_S  \\\n","0        0.0        0.0       0.0  ...         1.0         0.0         0.0   \n","1        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","2        0.0        0.0       0.0  ...         0.0         1.0         0.0   \n","3        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","4        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","5        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","6        0.0        0.0       0.0  ...         0.0         0.0         1.0   \n","7        0.0        0.0       0.0  ...         1.0         0.0         0.0   \n","8        0.0        0.0       0.0  ...         1.0         0.0         0.0   \n","9        0.0        0.0       0.0  ...         0.0         0.0         0.0   \n","\n","   embarked_rare  title_Mr  title_Mrs  title_rare  y_true  y_pred  proba_pred  \n","0            0.0       1.0        0.0         0.0       0       1    0.502177  \n","1            0.0       1.0        0.0         0.0       0       0    0.481497  \n","2            0.0       0.0        0.0         0.0       0       1    0.513358  \n","3            0.0       1.0        0.0         0.0       0       0    0.481422  \n","4            0.0       1.0        0.0         0.0       0       0    0.481452  \n","5            0.0       1.0        0.0         0.0       1       0    0.477030  \n","6            0.0       0.0        0.0         0.0       1       1    0.514231  \n","7            0.0       1.0        0.0         0.0       1       1    0.501921  \n","8            0.0       0.0        0.0         0.0       1       1    0.534687  \n","9            0.0       0.0        0.0         0.0       1       1    0.531581  \n","\n","[10 rows x 23 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["tmp = pd.DataFrame(X_test, columns=list(sort_feats.ordered_features))\n","tmp['y_true'] = np.array(y_test)\n","tmp['y_pred'] = model.predict(X_test)\n","tmp['proba_pred'] = model.predict_proba(X_test)[:,1]\n","\n","tmp.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpGi0xipTe9S"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}